---
title: useChat Integration
description: Integrate @built-in-ai/core with the useChat hook in AI SDK v6
---

## Overview

When using this library with the `useChat` hook, you'll need to create a [custom transport](https://ai-sdk.dev/docs/ai-sdk-ui/transport) implementation to handle client-side AI with download progress.

## BuiltInAIUIMessage Type

Import `BuiltInAIUIMessage` from `@built-in-ai/core` that extends `UIMessage` to include data parts such as download progress.

```typescript
import type { BuiltInAIUIMessage } from "@built-in-ai/core";

// BuiltInAIUIMessage extends UIMessage with custom data parts:
// - modelDownloadProgress: { status, progress?, message }
// - notification: { message, level }
```

### Type Definition

```typescript
type BuiltInAIUIMessage = UIMessage<
  never,
  {
    modelDownloadProgress: {
      status: "downloading" | "complete" | "error";
      progress?: number;
      message: string;
    };
    notification: {
      message: string;
      level: "info" | "warning" | "error";
    };
  }
>;
```

## Data Parts

### modelDownloadProgress

Tracks browser AI model download status and progress:

- `status`: Current download state (`"downloading"`, `"complete"`, or `"error"`)
- `progress`: Optional number from 0-1 indicating download progress
- `message`: Human-readable status message

### notification

Displays temporary messages and alerts to users:

- `message`: The notification text
- `level`: Severity level (`"info"`, `"warning"`, or `"error"`)

## Complete Example

See the complete working example in the repository:

- **Transport implementation**: [`/examples/next-hybrid/app/(core)/util/client-side-chat-transport.ts`](https://github.com/jakobhoeg/built-in-ai/blob/main/examples/next-hybrid/app/(core)/util/client-side-chat-transport.ts)
- **Page component**: [`/examples/next-hybrid/app/(core)/page.tsx`](https://github.com/jakobhoeg/built-in-ai/blob/main/examples/next-hybrid/app/(core)/page.tsx)

### What the Example Includes

- Download progress with UI progress bar and status message updates
- Hybrid client/server architecture with fallback
- Error handling and notifications
- Full integration with `useChat` hook

## Basic Transport Structure

Here's a simplified example of how to structure a custom transport:

```typescript
import { builtInAI, doesBrowserSupportBuiltInAI } from "@built-in-ai/core";
import { streamText } from "ai";
import type { UIMessageStreamWriter } from "ai";

export function createBuiltInAITransport() {
  return async ({ messages, onStream }) => {
    if (!doesBrowserSupportBuiltInAI()) {
      throw new Error("Built-in AI not supported");
    }

    const model = builtInAI();
    const availability = await model.availability();

    if (availability === "downloadable") {
      // Stream download progress to UI
      await model.createSessionWithProgress((progress) => {
        onStream?.writeData({
          type: "modelDownloadProgress",
          status: "downloading",
          progress,
          message: `Downloading model: ${Math.round(progress * 100)}%`,
        });
      });
    }

    const result = await streamText({
      model,
      messages,
    });

    // Stream the response
    for await (const chunk of result.textStream) {
      onStream?.writeText(chunk);
    }
  };
}
```

<Callout type="info">
  For production use, refer to the complete example in the repository which includes proper error handling, abort signals, and edge cases.
</Callout>

