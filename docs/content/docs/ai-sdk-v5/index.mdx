---
title: Getting Started
description: Introduction to using @browser-ai packages with Vercel AI SDK v5
---

<Callout type="info">
  This documentation covers packages compatible with AI SDK v5. For AI SDK v6 documentation, please visit the [AI SDK v6 section](/docs/ai-sdk-v6).
</Callout>

## Package Versions for AI SDK v5

| Package                       | AI SDK v5 | 
| ----------------------------- | :-------: | 
| `@browser-ai/core`            | ✓ `1.0.0` |
| `@browser-ai/transformers-js` | ✓ `1.0.0` | 
| `@browser-ai/web-llm`         | ✓ `1.0.0` | 

## Installation

```bash
# For Chrome/Edge built-in browser AI (Prompt API)
npm i @browser-ai/core@1.0.0

# For Transformers.js (Hugging Face models)
npm i @browser-ai/transformers-js@1.0.0

# For WebLLM (MLC models)
npm i @browser-ai/web-llm@1.0.0
```

## Available Packages

### @browser-ai/core

Access Chrome and Edge's built-in browser AI capabilities through the experimental [Prompt API](https://github.com/webmachinelearning/prompt-api). This package provides:

- **Language Models**: Text generation with Gemini Nano (Chrome) or Phi Mini (Edge)
- **Text Embeddings**: Generate embeddings using browser-native models
- **Multimodal Support**: Image and audio input
- **Tool Calling**: Function calling support

### @browser-ai/transformers-js

Run [Hugging Face Transformers](https://github.com/huggingface/transformers.js) models directly in the browser or server-side:

- **Open-source Language Models**: SmolLM, Qwen, Llama, and more
- **Text Embeddings**: GTE, MiniLM, and other embedding models
- **Vision Models**: SmolVLM and other multimodal models
- **Web Worker Support**: Efficient background processing
- **Transcription**: Whisper models for speech-to-text
- **Tool Calling**: Function calling support

### @browser-ai/web-llm

High-performance in-browser LLM inference using [WebLLM](https://github.com/mlc-ai/web-llm) with WebGPU:

- **Open-source Language Models**: Llama, Qwen, Phi, and many more
- **Download Progress**: Real-time model download tracking
- **Web Worker Support**: Efficient background processing
- **Tool Calling**: Function calling support

## Quick Start Example

Here's a simple example using `@browser-ai/core` with the AI SDK:

```typescript
import { streamText } from "ai";
import { browserAI } from "@browser-ai/core";

const result = streamText({
  model: browserAI(),
  messages: [{ role: "user", content: "Hello, how are you?" }],
});

for await (const chunk of result.textStream) {
  console.log(chunk);
}
```

<Callout type="warn">
  WebGPU is recommended for optimal performance with `transformers-js` and `web-llm`. Check [WebGPU browser support](https://caniuse.com/webgpu) for the latest compatibility information.
</Callout>