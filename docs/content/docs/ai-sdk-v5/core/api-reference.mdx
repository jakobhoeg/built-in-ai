---
title: API Reference
description: Complete API documentation for @built-in-ai/core
---

## Provider Functions

### `builtInAI(modelId?, settings?)`

Creates a browser AI model instance for chat.

**Parameters:**
- `modelId` (optional): The model identifier, defaults to `'text'`
- `settings` (optional): Configuration options
  - `temperature?: number` - Controls randomness (0-1)
  - `topK?: number` - Limits vocabulary selection

**Returns:** `BuiltInAIChatLanguageModel`

**Example:**

```typescript
import { builtInAI } from "@built-in-ai/core";

// Default configuration
const model = builtInAI();

// With custom settings
const modelWithSettings = builtInAI("text", {
  temperature: 0.7,
  topK: 40,
});
```

### `builtInAI.textEmbedding(modelId, settings?)`

Creates an embedding model instance.

**Parameters:**
- `modelId`: Must be `'embedding'`
- `settings` (optional): Configuration options
  - `wasmLoaderPath?: string` - Path to WASM loader (default: CDN hosted)
  - `wasmBinaryPath?: string` - Path to WASM binary (default: CDN hosted)
  - `modelAssetPath?: string` - Path to model asset file (default: CDN hosted)
  - `l2Normalize?: boolean` - Normalize with L2 norm (default: false)
  - `quantize?: boolean` - Quantize embeddings to bytes (default: false)
  - `delegate?: 'CPU' | 'GPU'` - Backend for inference

**Returns:** `BuiltInAIEmbeddingModel`

**Example:**

```typescript
import { builtInAI } from "@built-in-ai/core";
import { embed } from "ai";

const embeddingModel = builtInAI.textEmbedding("embedding", {
  l2Normalize: true,
  delegate: "GPU",
});

const { embedding } = await embed({
  model: embeddingModel,
  value: "Hello, world!",
});
```

---

## Utility Functions

### `doesBrowserSupportBuiltInAI()`

Quick check if the browser supports the built-in AI API. Useful for component-level decisions and feature flags.

**Returns:** `boolean` - `true` if browser supports the Prompt API, `false` otherwise

**Example:**

```typescript
import { doesBrowserSupportBuiltInAI } from "@built-in-ai/core";

if (doesBrowserSupportBuiltInAI()) {
  // Show built-in AI option in UI
} else {
  // Show server-side option only
}
```

---

## Model Methods

### `BuiltInAIChatLanguageModel.availability()`

Checks the current availability status of the built-in AI model.

**Returns:** `Promise<"unavailable" | "downloadable" | "downloading" | "available">`

| Status | Description |
|--------|-------------|
| `"unavailable"` | Model is not supported in the browser |
| `"downloadable"` | Model is supported but needs to be downloaded first |
| `"downloading"` | Model is currently being downloaded |
| `"available"` | Model is ready to use |

**Example:**

```typescript
const model = builtInAI();
const status = await model.availability();

switch (status) {
  case "unavailable":
    console.log("Use server-side model instead");
    break;
  case "downloadable":
    console.log("Model needs to be downloaded");
    break;
  case "downloading":
    console.log("Download in progress...");
    break;
  case "available":
    console.log("Ready to use!");
    break;
}
```

### `BuiltInAIChatLanguageModel.createSessionWithProgress(onProgress?)`

Creates a language model session with optional download progress monitoring.

**Parameters:**
- `onDownloadProgress?: (progress: number) => void` - Optional callback that receives progress values from 0 to 1 during model download

**Returns:** `Promise<LanguageModel>` - The configured language model session

**Example:**

```typescript
const model = builtInAI();

await model.createSessionWithProgress((progress) => {
  console.log(`Download: ${Math.round(progress * 100)}%`);
  // Update UI progress bar
});

// Model is now ready for use
```

---

## Types

### `BuiltInAIUIMessage`

Extended UI message type for use with the `useChat` hook that includes custom data parts for built-in AI functionality.

```typescript
type BuiltInAIUIMessage = UIMessage<
  never,
  {
    modelDownloadProgress: {
      status: "downloading" | "complete" | "error";
      progress?: number;
      message: string;
    };
    notification: {
      message: string;
      level: "info" | "warning" | "error";
    };
  }
>;
```

**Data Parts:**

| Part | Description |
|------|-------------|
| `modelDownloadProgress` | Tracks browser AI model download status and progress |
| `notification` | Displays temporary messages and alerts to users |

**Usage:**

```typescript
import type { BuiltInAIUIMessage } from "@built-in-ai/core";

// Use with useChat for proper typing
const { messages } = useChat<BuiltInAIUIMessage>({
  // ...
});
```

